import os
import pyarrow.parquet as pq

def merge_and_clean_parquets(base_dir="/opt/spark/data_lake/formatted/nba_api/games/"):
    print(f"ğŸ” Dossier Ã  traiter: {base_dir}")
    dates = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]
    
    for date in dates:
        folder = os.path.join(base_dir, date)
        parquet_files = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith(".parquet")]

        if not parquet_files:
            print(f"âš ï¸ Aucun fichier Parquet trouvÃ© pour {date}")
            continue

        print(f"ğŸ“¦ Fusion des fichiers Parquet pour {date}")
        dataset = pq.ParquetDataset(parquet_files)
        table = dataset.read()
        output_file = os.path.join(folder, "games.parquet")
        pq.write_table(table, output_file)

        print(f"âœ… Fichier unique sauvegardÃ©: {output_file}")

        # Supprimer les anciens part-*.parquet
        for f in parquet_files:
            if os.path.exists(f):
                os.remove(f)
        print(f"ğŸ§¹ Anciens part-* supprimÃ©s pour {date}")

    print("ğŸ‰ Worker 2 terminÃ©â€¯!")
